{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5748fa42",
   "metadata": {},
   "source": [
    "# üìì Notebook POC : Benchmark Scientifique (IoU & Latence)\n",
    "\n",
    "## 1. Contexte et Objectifs\n",
    "**Objectif :** √âvaluer quantitativement la pr√©cision (IoU) et la vitesse de deux mod√®les de d√©tourage sur un jeu de donn√©es r√©el.\n",
    "**Dataset :** [Human Parsing Dataset](https://huggingface.co/datasets/mattmdjaga/human_parsing_dataset) (Images contenant des humains + Masques de segmentation segment√©s par parties du corps).\n",
    "\n",
    "**Mod√®les compar√©s :**\n",
    "1.  **DeepLabV3 (Baseline 2017) :** Segmentation s√©mantique classique.\n",
    "2.  **RMBG-1.4 (SOTA 2024) :** Segmentation saillante optimis√©e pour le d√©tourage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c953f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environnement d'ex√©cution : cpu\n",
      "T√©l√©chargement du dataset...\n",
      "Dataset charg√©. Nombre total d'images disponibles : 17706\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torchvision.models.segmentation import deeplabv3_resnet101, DeepLabV3_ResNet101_Weights\n",
    "from transformers import AutoModelForImageSegmentation\n",
    "from datasets import load_dataset\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "dataset_full = load_dataset(\"mattmdjaga/human_parsing_dataset\", split=\"train\")\n",
    "dataset = dataset_full"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ae7a17",
   "metadata": {},
   "source": [
    "## 3. Pr√©paration des M√©triques et Utilitaires\n",
    "\n",
    "Le dataset fournit des masques o√π chaque partie du corps (bras, t√™te, jambes) a une valeur diff√©rente. Pour le d√©tourage, nous devons convertir cela en masque binaire : **0 = Fond, 1 = Humain**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5350971c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torchvision.models.segmentation import deeplabv3_resnet101, DeepLabV3_ResNet101_Weights\n",
    "from transformers import AutoModelForImageSegmentation\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def get_binary_mask(mask_pil):\n",
    "    return (np.array(mask_pil) > 0).astype(np.uint8)\n",
    "\n",
    "def compute_iou(pred, target):\n",
    "    if pred.shape != target.shape: return 0.0\n",
    "    inter = np.logical_and(pred, target).sum()\n",
    "    union = np.logical_or(pred, target).sum()\n",
    "    return inter / union if union > 0 else 1.0\n",
    "\n",
    "def extract_tensor(data):\n",
    "    if isinstance(data, torch.Tensor): return data\n",
    "    if isinstance(data, (list, tuple)):\n",
    "        for item in data:\n",
    "            found = extract_tensor(item)\n",
    "            if found is not None: return found  # Correction ici\n",
    "    return None\n",
    "\n",
    "def run_deeplab(img, model, prep):\n",
    "    start = time.time()\n",
    "    input_batch = prep(img).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        out = model(input_batch)['out'][0]\n",
    "        preds = out.argmax(0).byte().cpu().numpy()\n",
    "    mask = (preds == 15).astype(np.uint8)\n",
    "    if mask.sum() == 0: mask = (preds > 0).astype(np.uint8)\n",
    "    mask_res = Image.fromarray(mask * 255).resize(img.size, resample=Image.NEAREST)\n",
    "    return (np.array(mask_res) > 128).astype(np.uint8), time.time() - start\n",
    "\n",
    "def run_rmbg(img, model):\n",
    "    start = time.time()\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((1024, 1024)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5, 0.5, 0.5], [1.0, 1.0, 1.0])\n",
    "    ])\n",
    "    input_batch = transform(img).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        out = model(input_batch)\n",
    "        # La correction dans extract_tensor va emp√™cher le crash ici\n",
    "        preds = torch.sigmoid(extract_tensor(out)).cpu().squeeze()\n",
    "    mask_res = transforms.ToPILImage()(preds).resize(img.size, resample=Image.BILINEAR)\n",
    "    return (np.array(mask_res) > 128).astype(np.uint8), time.time() - start\n",
    "\n",
    "# Mod√®les\n",
    "weights = DeepLabV3_ResNet101_Weights.DEFAULT\n",
    "model_dl = deeplabv3_resnet101(weights=weights).to(device).eval()\n",
    "prep_dl = weights.transforms()\n",
    "\n",
    "model_rmbg = AutoModelForImageSegmentation.from_pretrained(\"briaai/RMBG-1.4\", trust_remote_code=True).to(device).eval()\n",
    "\n",
    "# Benchmark\n",
    "NUM_SAMPLES = 20\n",
    "indices = np.random.choice(len(dataset), NUM_SAMPLES, replace=False)\n",
    "metrics = []\n",
    "\n",
    "for idx in indices:\n",
    "    sample = dataset[int(idx)]\n",
    "    img = sample['image'].convert(\"RGB\")\n",
    "    gt = get_binary_mask(sample['mask'])\n",
    "    \n",
    "    m_dl, t_dl = run_deeplab(img, model_dl, prep_dl)\n",
    "    m_rmbg, t_rmbg = run_rmbg(img, model_rmbg)\n",
    "    \n",
    "    metrics.append({\n",
    "        \"id\": idx,\n",
    "        \"iou_deeplab\": compute_iou(m_dl, gt),\n",
    "        \"time_deeplab\": t_dl,\n",
    "        \"iou_rmbg\": compute_iou(m_rmbg, gt),\n",
    "        \"time_rmbg\": t_rmbg\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "25160cd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepLabV3 :\n",
      "- Pr√©cision (IoU) : 86.90%\n",
      "- Temps moyen     : 2.7151 secondes\n",
      "\n",
      " RMBG-1.4 (SOTA) :\n",
      "- Pr√©cision (IoU) : 90.53%\n",
      "- Temps moyen     : 1.3381 secondes\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.DataFrame(metrics)\n",
    "\n",
    "means = df.mean(numeric_only=True)\n",
    "\n",
    "\n",
    "# Affichage format√© : {:.2%} pour pourcentage, {:.4f} pour 4 d√©cimales\n",
    "print(f\"DeepLabV3 :\")\n",
    "print(f\"- Pr√©cision (IoU) : {means['iou_deeplab']:.2%}\")\n",
    "print(f\"- Temps moyen     : {means['time_deeplab']:.4f} secondes\")\n",
    "\n",
    "print(f\"\\n RMBG-1.4 (SOTA) :\")\n",
    "print(f\"- Pr√©cision (IoU) : {means['iou_rmbg']:.2%}\")\n",
    "print(f\"- Temps moyen     : {means['time_rmbg']:.4f} secondes\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
