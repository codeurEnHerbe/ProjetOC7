{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5748fa42",
   "metadata": {},
   "source": [
    "# ðŸ““ Notebook POC : Benchmark Scientifique (IoU & Latence)\n",
    "\n",
    "## 1. Contexte et Objectifs\n",
    "**Objectif :** Ã‰valuer quantitativement la prÃ©cision (IoU) et la vitesse de deux modÃ¨les de dÃ©tourage sur un jeu de donnÃ©es rÃ©el.\n",
    "**Dataset :** [Human Parsing Dataset](https://huggingface.co/datasets/mattmdjaga/human_parsing_dataset) (Images contenant des humains + Masques de segmentation segmentÃ©s par parties du corps).\n",
    "\n",
    "**ModÃ¨les comparÃ©s :**\n",
    "1.  **DeepLabV3 (Baseline 2017) :** Segmentation sÃ©mantique classique.\n",
    "2.  **RMBG-1.4 (SOTA 2024) :** Segmentation saillante optimisÃ©e pour le dÃ©tourage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c953f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environnement d'exÃ©cution : cpu\n",
      "TÃ©lÃ©chargement du dataset...\n",
      "Dataset chargÃ©. Nombre total d'images disponibles : 17706\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torchvision.models.segmentation import deeplabv3_resnet101, DeepLabV3_ResNet101_Weights\n",
    "from transformers import AutoModelForImageSegmentation\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Configuration du device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Environnement d'exÃ©cution : {device}\")\n",
    "\n",
    "# --- Chargement du Dataset ---\n",
    "print(\"TÃ©lÃ©chargement du dataset...\")\n",
    "\n",
    "# Le dataset n'a qu'un split 'train', on le charge\n",
    "dataset_full = load_dataset(\"mattmdjaga/human_parsing_dataset\", split=\"train\")\n",
    "\n",
    "# On simule un split de test en prenant un Ã©chantillon alÃ©atoire (ex: 20% ou juste 50 images pour le POC)\n",
    "# Pour aller vite, on va juste piocher alÃ©atoirement dans le dataset complet plus tard\n",
    "print(f\"Dataset chargÃ©. Nombre total d'images disponibles : {len(dataset_full)}\")\n",
    "dataset = dataset_full # On garde la rÃ©fÃ©rence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ae7a17",
   "metadata": {},
   "source": [
    "## 3. PrÃ©paration des MÃ©triques et Utilitaires\n",
    "\n",
    "Le dataset fournit des masques oÃ¹ chaque partie du corps (bras, tÃªte, jambes) a une valeur diffÃ©rente. Pour le dÃ©tourage, nous devons convertir cela en masque binaire : **0 = Fond, 1 = Humain**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5350971c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargement des modÃ¨les en mÃ©moire...\n",
      "\n",
      "ðŸš€ Lancement du Benchmark sur 20 images...\n",
      "\n",
      "==================================================\n",
      " RÃ‰SULTATS DU BENCHMARK SCIENTIFIQUE\n",
      "==================================================\n",
      "ModÃ¨le Classique (DeepLabV3) | IoU Moyen: 88.64% | Temps Moyen: 2.562s\n",
      "ModÃ¨le SOTA (RMBG-1.4)       | IoU Moyen: 90.07% | Temps Moyen: 1.304s\n",
      "--------------------------------------------------\n",
      "GAIN DE PRÃ‰CISION (SOTA) : +1.4 points de pourcentage\n",
      "GAIN DE VITESSE (SOTA)   : +49.1 % plus rapide\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torchvision.models.segmentation import deeplabv3_resnet101, DeepLabV3_ResNet101_Weights\n",
    "from transformers import AutoModelForImageSegmentation\n",
    "\n",
    "# Configuration Device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# --- 1. FONCTIONS UTILITAIRES & MÃ‰TRIQUES ---\n",
    "\n",
    "def preprocess_ground_truth(mask_pil):\n",
    "    \"\"\"Convertit le masque colorÃ© du dataset en masque binaire (0=Fond, 1=Humain)\"\"\"\n",
    "    mask_np = np.array(mask_pil)\n",
    "    # Dans ce dataset, le fond est 0, tout le reste (parties du corps) est > 0\n",
    "    binary_mask = (mask_np > 0).astype(np.uint8)\n",
    "    return binary_mask\n",
    "\n",
    "def calculate_iou(pred_mask, true_mask):\n",
    "    \"\"\"Calcule l'IoU (Intersection over Union) entre deux masques binaires\"\"\"\n",
    "    if pred_mask.shape != true_mask.shape:\n",
    "        return 0.0\n",
    "    intersection = np.logical_and(pred_mask, true_mask).sum()\n",
    "    union = np.logical_or(pred_mask, true_mask).sum()\n",
    "    return intersection / union if union > 0 else (1.0 if intersection == 0 else 0.0)\n",
    "\n",
    "def find_tensor(data):\n",
    "    \"\"\"Cherche le tenseur image dans les sorties complexes des modÃ¨les HuggingFace\"\"\"\n",
    "    if isinstance(data, torch.Tensor): return data\n",
    "    if isinstance(data, (list, tuple)):\n",
    "        for item in data:\n",
    "            found = find_tensor(item)\n",
    "            if found is not None: return found\n",
    "    return None\n",
    "\n",
    "# --- 2. MOTEURS D'INFÃ‰RENCE ---\n",
    "\n",
    "def run_deeplab(image, model, preprocess):\n",
    "    start = time.time()\n",
    "    input_tensor = preprocess(image).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor)['out'][0]\n",
    "        preds = output.argmax(0).byte().cpu().numpy()\n",
    "    # Classe 15 = Personne\n",
    "    mask = (preds == 15).astype(np.uint8)\n",
    "    if mask.sum() == 0: mask = (preds > 0).astype(np.uint8) # Fallback\n",
    "    \n",
    "    # Resize pour correspondre Ã  la vÃ©ritÃ© terrain\n",
    "    mask_pil = Image.fromarray(mask * 255).resize(image.size, resample=Image.NEAREST)\n",
    "    return (np.array(mask_pil) > 128).astype(np.uint8), time.time() - start\n",
    "\n",
    "def run_rmbg(image, model):\n",
    "    start = time.time()\n",
    "    w, h = image.size\n",
    "    # Preprocessing spÃ©cifique RMBG\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((1024, 1024)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5, 0.5, 0.5], [1.0, 1.0, 1.0])\n",
    "    ])\n",
    "    input_tensor = transform(image).unsqueeze(0).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        raw_output = model(input_tensor)\n",
    "        tensor = find_tensor(raw_output)\n",
    "        preds = torch.sigmoid(tensor).cpu().squeeze()\n",
    "    \n",
    "    # Resize propre\n",
    "    mask_pil = transforms.ToPILImage()(preds)\n",
    "    mask_resized = mask_pil.resize((w, h), resample=Image.BILINEAR)\n",
    "    return (np.array(mask_resized) > 128).astype(np.uint8), time.time() - start\n",
    "\n",
    "# --- 3. CHARGEMENT DES MODÃˆLES ---\n",
    "print(\"Chargement des modÃ¨les en mÃ©moire...\")\n",
    "# DeepLab\n",
    "w_classic = DeepLabV3_ResNet101_Weights.DEFAULT\n",
    "model_classic = deeplabv3_resnet101(weights=w_classic).to(device).eval()\n",
    "pre_classic = w_classic.transforms()\n",
    "\n",
    "# RMBG-1.4\n",
    "model_sota = AutoModelForImageSegmentation.from_pretrained(\"briaai/RMBG-1.4\", trust_remote_code=True).to(device).eval()\n",
    "\n",
    "# --- 4. EXÃ‰CUTION DU BENCHMARK ---\n",
    "\n",
    "NUM_SAMPLES = 20  # Nombre d'images pour le test\n",
    "results = []\n",
    "\n",
    "print(f\"\\nðŸš€ Lancement du Benchmark sur {NUM_SAMPLES} images...\")\n",
    "indices = np.random.choice(len(dataset), NUM_SAMPLES, replace=False)\n",
    "\n",
    "for idx in indices:\n",
    "    sample = dataset[int(idx)]\n",
    "    img = sample['image'].convert(\"RGB\")\n",
    "    gt_mask = preprocess_ground_truth(sample['mask']) # Masque \"VÃ©ritÃ© Terrain\"\n",
    "    \n",
    "    # Test Classique\n",
    "    mask_c, t_c = run_deeplab(img, model_classic, pre_classic)\n",
    "    iou_c = calculate_iou(mask_c, gt_mask)\n",
    "    \n",
    "    # Test SOTA\n",
    "    mask_s, t_s = run_rmbg(img, model_sota)\n",
    "    iou_s = calculate_iou(mask_s, gt_mask)\n",
    "    \n",
    "    results.append({\n",
    "        \"Image\": idx,\n",
    "        \"DeepLab IoU\": iou_c, \"DeepLab Time\": t_c,\n",
    "        \"RMBG IoU\": iou_s, \"RMBG Time\": t_s\n",
    "    })\n",
    "\n",
    "# --- 5. RÃ‰SULTATS ET COMPARAISON ---\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\" RÃ‰SULTATS DU BENCHMARK SCIENTIFIQUE\")\n",
    "print(\"=\"*50)\n",
    "print(f\"ModÃ¨le Classique (DeepLabV3) | IoU Moyen: {df['DeepLab IoU'].mean():.2%} | Temps Moyen: {df['DeepLab Time'].mean():.3f}s\")\n",
    "print(f\"ModÃ¨le SOTA (RMBG-1.4)       | IoU Moyen: {df['RMBG IoU'].mean():.2%} | Temps Moyen: {df['RMBG Time'].mean():.3f}s\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Gains\n",
    "gain_iou = (df['RMBG IoU'].mean() - df['DeepLab IoU'].mean()) * 100\n",
    "gain_time = (df['DeepLab Time'].mean() - df['RMBG Time'].mean()) / df['DeepLab Time'].mean() * 100\n",
    "\n",
    "print(f\"GAIN DE PRÃ‰CISION (SOTA) : {gain_iou:+.1f} points de pourcentage\")\n",
    "print(f\"GAIN DE VITESSE (SOTA)   : {gain_time:+.1f} % plus rapide\")\n",
    "print(\"=\"*50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
